{"learning_rate": 0.0005748708832034106, "dropout": 0.1373681640625, "lr_decay": 0.00022252929687500002, "momentum": 0.8525219726562501, "L2_reg": 3.95590771484375, "batch_norm": false, "standardize": false, "n_in": 10, "hidden_layers_sizes": [14, 14], "activation": "selu"}